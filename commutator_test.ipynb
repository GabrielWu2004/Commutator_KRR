{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from KernelRidge_commutator import generate_CM, KRR_commutator\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import warnings\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('qm9_data.npz', allow_pickle=True)\n",
    "coords = data['coordinates']\n",
    "nuclear_charges = data['charges']\n",
    "elements = data['elements']\n",
    "energies = np.array(data['H_atomization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_mol = energies.shape[0]\n",
    "cm = np.zeros((num_mol, 29, 29))\n",
    "for i in range(num_mol):\n",
    "    cm[i] = generate_CM(coords[i], nuclear_charges[i], pad=29)\n",
    "\n",
    "print(cm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(data.keys())\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(elements[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cm[:5000]\n",
    "y = energies.reshape(-1, 1)[:5000]\n",
    "params = {'lambda': 1e-3, 'length': 1}\n",
    "mae_scores = []\n",
    "\n",
    "kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "for fold, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    preds = KRR_commutator(X_train, y_train, X_test, params, kernel='rbf')\n",
    "    score = mean_absolute_error(preds.reshape(-1, 1), y_test)\n",
    "    mae_scores.append(score)\n",
    "    print(f\"fold {fold+1}: MAE = {score}\")\n",
    "\n",
    "print(f\"Average MAE: {np.array(mae_scores).mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cm[:2000]\n",
    "y = energies.reshape(-1, 1)[:2000]\n",
    "\n",
    "def objective(params):\n",
    "    mae_scores = []\n",
    "    kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    for fold, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        preds = KRR_commutator(X_train, y_train, X_test, params, kernel='rbf')\n",
    "        if type(preds) is str:\n",
    "            return np.inf\n",
    "        score = mean_absolute_error(preds.reshape(-1, 1), y_test)\n",
    "        mae_scores.append(score)\n",
    "    return np.array(mae_scores).mean()\n",
    "\n",
    "space = {\n",
    "    'lambda': hp.loguniform('lambda', -30, 0), \n",
    "    'length': hp.loguniform('length', -2, 2)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=50,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    mae_scores = []\n",
    "    kfold = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "    for fold, (train_index, test_index) in enumerate(kfold.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        preds = KRR_commutator(X_train, y_train, X_test, params, kernel='laplacian')\n",
    "        if type(preds) is str:\n",
    "            return np.inf\n",
    "        score = mean_absolute_error(preds.reshape(-1, 1), y_test)\n",
    "        mae_scores.append(score)\n",
    "    return np.array(mae_scores).mean()\n",
    "\n",
    "space = {\n",
    "    'lambda': hp.loguniform('lambda', -30, 0), \n",
    "    'length': hp.loguniform('length', -2, 2)\n",
    "}\n",
    "\n",
    "trials = Trials()\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest, # tree parzen estimator\n",
    "                max_evals=50,\n",
    "                trials=trials)\n",
    "\n",
    "print(\"Best hyperparameters:\", best)\n",
    "print(\"Loss:\", trials.best_trial['result']['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_flatten = cm.reshape((cm.shape[0], -1))\n",
    "print(cm_flatten.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cm_flatten[:2000]\n",
    "y = energies.reshape(-1, 1)[:2000]\n",
    "\n",
    "params = {'alpha': 1e-5, 'gamma': 1e-5, 'kernel': 'rbf'}\n",
    "model = KernelRidge(**params)\n",
    "\n",
    "neg_mae_scores = cross_val_score(model, X, y, scoring = 'neg_mean_absolute_error', cv=2)\n",
    "mae_scores = -neg_mae_scores\n",
    "print(mae_scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curve ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cm[:10000]\n",
    "y = energies.reshape(-1, 1)[:10000]\n",
    "\n",
    "gaussian_error = []\n",
    "laplacian_error = []\n",
    "training_size = [i*1000 for i in range(1, 10, 2)]\n",
    "\n",
    "best_params_gaussian = {'lambda': 7.882813671669788e-12, 'length': 0.7310621690634572}\n",
    "best_params_laplacian = {'lambda': 1.9168314543935938e-13, 'length': 6.657357327134051}\n",
    "\n",
    "for size in training_size:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-size/10000, random_state=42)\n",
    "    preds_gaussian = KRR_commutator(X_train, y_train, X_test, best_params_gaussian, kernel='rbf')\n",
    "    preds_laplacian = KRR_commutator(X_train, y_train, X_test, best_params_laplacian, kernel='laplacian')\n",
    "    score_gaussian = mean_absolute_error(preds_gaussian.reshape(-1, 1), y_test)\n",
    "    score_laplacian = mean_absolute_error(preds_laplacian.reshape(-1, 1), y_test)\n",
    "    gaussian_error.append(score_gaussian)\n",
    "    laplacian_error.append(score_laplacian)\n",
    "    print(f\"Training size: {size}. Gaussian MAE: {score_gaussian}. Laplacian MAE: {score_laplacian}\")\n",
    "\n",
    "print(gaussian_error)\n",
    "print(laplacian_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cm_flatten[:10000]\n",
    "y = energies.reshape(-1, 1)[:10000]\n",
    "\n",
    "normal_KRR_error = []\n",
    "training_size = [i*1000 for i in range(1, 10, 2)]\n",
    "\n",
    "best_params = {'alpha': 1e-5, 'gamma': 1e-5, 'kernel': 'rbf'}\n",
    "\n",
    "for size in training_size:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-size/10000, random_state=42)\n",
    "    model = KernelRidge(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    error = mean_absolute_error(preds, y_test)\n",
    "    normal_KRR_error.append(error)\n",
    "    print(f\"Training size: {size}. MAE: {error}.\")\n",
    "\n",
    "print(normal_KRR_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = training_size\n",
    "y1 = gaussian_error # [2.443359366444566, 2.4407461385715497, 2.4368748118001204, 2.4359856271244116, 2.4406070370001216]\n",
    "y2 = laplacian_error # [2.443359366444566, 2.4407461385715497, 2.4368748118001204, 2.4359856271244116, 2.4406070370001216]\n",
    "y3 = normal_KRR_error # [0.04285921037085594, 0.033405950159750446, 0.02982421188819421, 0.027342219954064845, 0.025942363605852427]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(x, y1, label='CM - Gaussian', marker='^', linestyle='-', linewidth=3, markersize=10)\n",
    "plt.plot(x, y2, label='CM - Laplacian', marker='^', linestyle='-', linewidth=3, markersize=10)\n",
    "plt.plot(x, y3, label='CM - Euclidean distance', marker='^', linestyle='-', linewidth=3, markersize=10)\n",
    "\n",
    "plt.title(\"Learning curve for commutator KRR with CM representation, atomization energy prediction\")\n",
    "plt.xlabel('Training size')\n",
    "plt.ylabel('MAE [Ha]')\n",
    "plt.legend()\n",
    "\n",
    "plt.xscale('log', base=10)\n",
    "plt.yscale('log', base=10)\n",
    "xticks = training_size\n",
    "yticks = [10, 1, 0.1, 0.01]\n",
    "plt.xticks(xticks, labels=xticks)\n",
    "plt.yticks(yticks, labels=yticks)\n",
    "\n",
    "plt.savefig(\"Learning_curve.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_1d(arr, batch_size=500):\n",
    "    num_rows = arr.shape[0]\n",
    "    distance_matrix = np.zeros((num_rows, num_rows))\n",
    "\n",
    "    for i in range(0, num_rows, batch_size):\n",
    "        end_idx_i = min(i + batch_size, num_rows)\n",
    "        batch_i = arr[i:end_idx_i]\n",
    "\n",
    "        for j in range(0, num_rows, batch_size):\n",
    "            end_idx_j = min(j + batch_size, num_rows)\n",
    "            batch_j = arr[j:end_idx_j]\n",
    "\n",
    "            # Calculate squared Euclidean distances between rows in the current batches\n",
    "            squared_distances = np.sum((batch_i[:, np.newaxis] - batch_j) ** 2, axis=2)\n",
    "\n",
    "            # Take the square root to get the actual Euclidean distances\n",
    "            distance_matrix[i:end_idx_i, j:end_idx_j] = np.sqrt(squared_distances)\n",
    "\n",
    "    return distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_dist= euclidean_distance_1d(cm_flatten[:10000])\n",
    "print(vec_dist.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_vec_dist = vec_dist.flatten()\n",
    "plt.hist(flattened_vec_dist, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.xlabel('Euclidean Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Euclidean Distances between CM vectors')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"Distribution of Euclidean Distances between CM vectors.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_2d(arr, batch_size=1000):\n",
    "    num_matrices = arr.shape[0]\n",
    "    num_rows = arr.shape[1]\n",
    "    distance_matrix = np.zeros((num_matrices, num_matrices))\n",
    "\n",
    "    for i in range(0, num_matrices, batch_size):\n",
    "        end_idx_i = min(i + batch_size, num_matrices)\n",
    "        batch_i = arr[i:end_idx_i]\n",
    "\n",
    "        for j in range(0, num_matrices, batch_size):\n",
    "            end_idx_j = min(j + batch_size, num_matrices)\n",
    "            batch_j = arr[j:end_idx_j]\n",
    "\n",
    "            # Calculate squared Euclidean distances between matrices in the current batches\n",
    "            squared_distances = np.sum((batch_i[:, np.newaxis] - batch_j) ** 2, axis=(2, 3))\n",
    "\n",
    "            # Take the square root to get the actual Euclidean distances\n",
    "            distance_matrix[i:end_idx_i, j:end_idx_j] = np.sqrt(squared_distances)\n",
    "\n",
    "    return distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dist = euclidean_distance_2d(cm[:10000])\n",
    "print(matrix_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_matrix_dist = matrix_dist.flatten()\n",
    "plt.hist(flattened_matrix_dist, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.xlabel('Euclidean Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Euclidean Distances between CM matrices')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"Distribution of Euclidean Distances between CM matrices.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commutator Distribution ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commutator_distance_matrix_batched(arr, batch_size=1000):\n",
    "    num_matrices = arr.shape[0]\n",
    "    num_rows = arr.shape[1]\n",
    "    distance_matrix = np.zeros((num_matrices, num_matrices))\n",
    "\n",
    "    for i in range(0, num_matrices, batch_size):\n",
    "        end_idx_i = min(i + batch_size, num_matrices)\n",
    "        batch_i = arr[i:end_idx_i]\n",
    "\n",
    "        for j in range(0, num_matrices, batch_size):\n",
    "            end_idx_j = min(j + batch_size, num_matrices)\n",
    "            batch_j = arr[j:end_idx_j]\n",
    "\n",
    "            # Compute the commutator between matrices in the current batches\n",
    "            commutator = np.matmul(batch_i[:, np.newaxis], batch_j) - np.matmul(batch_j[:, np.newaxis], batch_i)\n",
    "            \n",
    "            # Calculate the Frobenius norm of the commutator\n",
    "            commutator_norm = np.linalg.norm(commutator, ord='fro', axis=(2, 3))\n",
    "\n",
    "            # Take the square root to get the actual commutator distances\n",
    "            distance_matrix[i:end_idx_i, j:end_idx_j] = commutator_norm\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the commutator distance matrix for matrices in batches of size 100\n",
    "commutator_dist = commutator_distance_matrix_batched(cm[:10000])\n",
    "print(commutator_dist.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the distance matrix into a 1D array\n",
    "flattened_commutator_dist = commutator_dist.flatten()\n",
    "\n",
    "# Create a histogram of the flattened distances\n",
    "plt.hist(flattened_commutator_dist, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.xlabel('Commutator Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Commutator Distances between Pairwise Matrices')\n",
    "plt.grid(True)\n",
    "# plt.savefig('Distribution of Commutator Distances between Pairwise Matrices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_sorted = np.sort(np.unique(flattened_commutator_dist))\n",
    "print(unique_sorted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mask = (flattened_commutator_dist == 0)\n",
    "num_zeros = np.count_nonzero(zero_mask)\n",
    "small_mask = (flattened_commutator_dist < 10)\n",
    "num_small = np.count_nonzero(small_mask)\n",
    "print(num_zeros)\n",
    "print(num_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commutator With Eigval ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch_commutator_eigval(args):\n",
    "    batch_i, batch_j = args\n",
    "    commutator = np.matmul(batch_i[:, np.newaxis], batch_j) - np.matmul(batch_j[:, np.newaxis], batch_i)\n",
    "    commutator_norm = np.linalg.norm(commutator, ord='fro', axis=(2, 3))\n",
    "    eigenvalue_diff_norm = np.linalg.norm(np.linalg.eigvals(batch_i) - np.linalg.eigvals(batch_j), ord=2, axis=1)\n",
    "    combined_norms = commutator_norm + eigenvalue_diff_norm\n",
    "    return combined_norms\n",
    "\n",
    "def commutator_distance_with_eigval_parallel(arr, batch_size=1000, num_processes=4):\n",
    "    num_matrices = arr.shape[0]\n",
    "    distance_matrix = np.zeros((num_matrices, num_matrices))\n",
    "\n",
    "    if num_processes is None:\n",
    "        num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "    pool = multiprocessing.Pool(processes=num_processes)\n",
    "\n",
    "    for i in range(0, num_matrices, batch_size):\n",
    "        end_idx_i = min(i + batch_size, num_matrices)\n",
    "        batch_i = arr[i:end_idx_i]\n",
    "\n",
    "        args_list = []\n",
    "        for j in range(0, num_matrices, batch_size):\n",
    "            end_idx_j = min(j + batch_size, num_matrices)\n",
    "            batch_j = arr[j:end_idx_j]\n",
    "            args_list.append((batch_i, batch_j))\n",
    "\n",
    "        results = pool.map(process_batch_commutator_eigval, args_list)\n",
    "\n",
    "        for j, result in enumerate(results):\n",
    "            end_idx_j = min(j + batch_size, num_matrices)\n",
    "            distance_matrix[i:end_idx_i, j:end_idx_j] = result\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    return distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def commutator_distance_with_eigval(arr, batch_size=1000):\n",
    "    num_matrices = arr.shape[0]\n",
    "    distance_matrix = np.zeros((num_matrices, num_matrices))\n",
    "\n",
    "    for i in range(0, num_matrices, batch_size):\n",
    "        end_idx_i = min(i + batch_size, num_matrices)\n",
    "        batch_i = arr[i:end_idx_i]\n",
    "\n",
    "        for j in range(0, num_matrices, batch_size):\n",
    "            end_idx_j = min(j + batch_size, num_matrices)\n",
    "            batch_j = arr[j:end_idx_j]\n",
    "\n",
    "            # Compute the commutator between matrices in the current batches\n",
    "            commutator = np.matmul(batch_i[:, np.newaxis], batch_j) - np.matmul(batch_j[:, np.newaxis], batch_i)\n",
    "            \n",
    "            # Calculate the Frobenius norm of the commutator\n",
    "            commutator_norm = np.linalg.norm(commutator, ord='fro', axis=(2, 3))\n",
    "\n",
    "            # Calculate the L2 norm of eigenvalue differences\n",
    "            eigenvalue_diff_norm = np.linalg.norm(np.linalg.eigvals(batch_i) - np.linalg.eigvals(batch_j), ord=2, axis=1)\n",
    "\n",
    "            # Combine the norms element-wise\n",
    "            combined_norms = commutator_norm + eigenvalue_diff_norm\n",
    "\n",
    "            # Update the distance matrix\n",
    "            distance_matrix[i:end_idx_i, j:end_idx_j] = combined_norms\n",
    "\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eigval_distance(arr, batch_size=1000):\n",
    "    num_matrices = arr.shape[0]\n",
    "    distance_matrix = np.zeros((num_matrices, num_matrices))\n",
    "\n",
    "    for i in range(0, num_matrices, batch_size):\n",
    "        end_idx_i = min(i + batch_size, num_matrices)\n",
    "        batch_i = arr[i:end_idx_i]\n",
    "\n",
    "        for j in range(0, num_matrices, batch_size):\n",
    "            end_idx_j = min(j + batch_size, num_matrices)\n",
    "            batch_j = arr[j:end_idx_j]\n",
    "\n",
    "            # Calculate the L2 norm of eigenvalue differences\n",
    "            eigenvalue_diff_norm = np.linalg.norm(np.linalg.eigvals(batch_i) - np.linalg.eigvals(batch_j), ord=2, axis=1) ** 2\n",
    "\n",
    "            # Update the distance matrix\n",
    "            distance_matrix[i:end_idx_i, j:end_idx_j] = eigenvalue_diff_norm\n",
    "\n",
    "    return distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigval_dist = eigval_distance(cm[:10000])\n",
    "print(eigval_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commutator_eigval_dist = eigval_dist + commutator_dist\n",
    "print(commutator_eigval_dist.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the distance matrix into a 1D array\n",
    "flattened_commutator_eigval = commutator_eigval_dist.flatten()\n",
    "flattened_eigval_dist = eigval_dist.flatten()\n",
    "\n",
    "# Create a histogram of the flattened distances\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 9))\n",
    "\n",
    "axes[0, 0].hist(flattened_commutator_dist, bins=50, alpha=0.7, color='red', edgecolor='black')\n",
    "axes[0, 0].set_title('Commutator Norm')\n",
    "axes[0, 0].set_xlabel('Norm')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[0, 1].hist(flattened_commutator_eigval, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "axes[0, 1].set_title('Commutator + Eigenvalue Norm')\n",
    "axes[0, 1].set_xlabel('Norm')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 0].hist(flattened_eigval_dist, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "axes[1, 0].set_title('Eigenvalue Norm')\n",
    "axes[1, 0].set_xlabel('Norm')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "\n",
    "axes[1, 1].hist(flattened_commutator_eigval, bins=50, alpha=0.7, color='blue', edgecolor='black', label=\"Commutator + Eigenvalue norm\")\n",
    "axes[1, 1].hist(flattened_commutator_dist, bins=50, alpha=0.7, color='red', edgecolor='black', label=\"Commutator norm\")\n",
    "axes[1, 1].set_title('Comparison')\n",
    "axes[1, 1].set_xlabel('Norm')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Comparing Distribution of Commutator and Eigenvalue Distance between Pairwise Matrices')\n",
    "plt.subplots_adjust(top=0.90, hspace=0.2)\n",
    "plt.grid(True)\n",
    "plt.savefig('Comparing Distribution of Commutator and Eigenvalue Distance between Pairwise Matrices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the distance matrix into a 1D array\n",
    "flattened_eigval_dist = eigval_dist.flatten()\n",
    "\n",
    "# Create a histogram of the flattened distances\n",
    "plt.hist(flattened_eigval_dist, bins=50, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.xlabel('Eigval Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Eigenvalue Distance between Pairwise Matrices')\n",
    "plt.grid(True)\n",
    "plt.savefig('Distribution of Eigenvalue Distance between Pairwise Matrices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_mask = (flattened_commutator_dist == 0)\n",
    "num_zeros = np.count_nonzero(zero_mask)\n",
    "zero_mask_w_eig = (flattened_commutator_eigval == 0)\n",
    "num_zeros_w_eig = np.count_nonzero(zero_mask_w_eig)\n",
    "print(num_zeros)\n",
    "print(num_zeros_w_eig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_indices = np.argwhere(commutator_eigval_dist == 0)\n",
    "print(zero_indices[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    index1, index2 = zero_indices[i][0], zero_indices[i][1]\n",
    "    print(f\"duplicate {i+1}:\")\n",
    "    print(elements[index1])\n",
    "    print(elements[index2])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
